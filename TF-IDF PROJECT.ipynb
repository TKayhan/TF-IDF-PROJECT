{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd7fa380",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = [\n",
    "    \"\"\"Description\n",
    "    We're looking for an experienced NLP & Search research engineer to work within AppGallery Search & Recommendation projects.\n",
    "\n",
    "    AppGallery is a package manager and application distribution platform, or marketplace 'app store', developed by Huawei for the Android operating system. AppGallery is used by 400+ million active users on 700+ million Huawei devices. Our team in Turkey is responsible for improving the AI driven search & recommendation capabilities of the application for the Asia, Africa, Latin America, Europe and Russia markets.\n",
    "\n",
    "    What can you expect in this role?\n",
    "\n",
    "    As a part of our research team you'll work with talented researchers and developers at every level to improve our search and recommendation solutions within AppGallery. This role allows you to directly affect user experience of millions of AppGallery users.\n",
    "\n",
    "    You'll have a chance to thrive in a multinational environment where you can work closely with other colleagues from China, Singapore and Ireland teams. Within this role you can expect to carry out following tasks;\n",
    "\n",
    "    Requirements\n",
    "    Design, develop, and optimize retrieval models (RMs) for efficient and accurate search functionality in app store domain.\n",
    "    Implement NLP techniques and train, evaluate (offline & online), optimize deep learning models to enhance semantic search capabilities.\n",
    "    Design, build and deploy scalable ML services on Huawei's MLOps platform to address business requirements.\n",
    "    Collaborate with cross-functional teams to analyze complex data requirements and design innovative software solutions.\n",
    "    Conduct code reviews to ensure high-quality, maintainable, and efficient code following industry best practices.\n",
    "    Mentor and guide junior engineers in the areas of search, information retrieval, deep learning, and NLP.\n",
    "    Stay updated with the latest advancements in search, information retrieval, deep learning, and NLP, and integrate them into our products and services.\n",
    "    Produce academic outputs in the form of papers, patents, and technical talks.\n",
    "\n",
    "    What are the qualifications to fit the role?\n",
    "\n",
    "    Minimum MS degree or PHD degree with focus on NLP, IR and DL, preferably in a computer science & engineering or related fields.\n",
    "    Minimum 3 years of experience preferably in industry.\n",
    "    Strong Python programming skills with proven experience crafting, prototyping, and delivering machine learning solutions into production.\n",
    "    Experience with popular deep learning frameworks (TensorFlow, PyTorch) and NLP libraries.\n",
    "    Publication records in journals or conferences related with NLP especially in the areas of vector search, dense retrieval, semantic search.\n",
    "    Experience in integrating retrieval models (RMs) for large-scale search engines using these specialized techniques.\n",
    "    Previous project experience in search or recommendation systems domain is a big plus.\n",
    "    Java service development experience using Spring and related topics & technologies is a plus (RESTful services, Redis, ElasticSearch, RDBMS)\n",
    "    Fluency in English is important, reading/writing skills in Russian and/or Arabic is a plus.\n",
    "\n",
    "    Am i right for the team?\n",
    "\n",
    "    If you're excellent in analysis, modeling and problem-solving, and can see the essence of problems from complex data, you can be perfect fit for the task at hand.\n",
    "    If you're easy to communicate, open for suggestions and improvements, can work independently, pro-actively and well aligned then you can be perfect fit for our team culture.\"\"\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6482bf38",
   "metadata": {},
   "source": [
    "### TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40f888e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d32d64de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tugbakayhan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52182138",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "word_set = []\n",
    "\n",
    "for sent in sample_text:\n",
    "    words = [word.lower() for word in word_tokenize(sent) if word.isalpha()]\n",
    "    sentences.append(words)\n",
    "    for word in words:\n",
    "        if word not in word_set:\n",
    "            word_set.append(word)\n",
    "# Set of words\n",
    "word_set = set(word_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d38bef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents:  1\n",
      "Total words:  252\n"
     ]
    }
   ],
   "source": [
    "# total documents in our corpus\n",
    "total_docs = len(sample_text)\n",
    "print('Total documents: ', total_docs)\n",
    "print('Total words: ', len(word_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ac5e13",
   "metadata": {},
   "source": [
    "### İNDEXİNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca97e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {}\n",
    "for i, word in enumerate(word_set):\n",
    "    word_index[word] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7163ce3d",
   "metadata": {},
   "source": [
    "### Create a dictionary to keep the count of the number of documents containing the given word.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59f5f507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ml': 1, 'store': 2, 'code': 2, 'reviews': 1, 'journals': 1, 'well': 1, 'to': 11, 'domain': 2, 'on': 3, 'popular': 1, 'open': 1, 'latin': 1, 'app': 1, 'every': 1, 'technical': 1, 'solutions': 3, 'china': 1, 'develop': 1, 'service': 1, 'mentor': 1, 'evaluate': 1, 'areas': 2, 'latest': 1, 'previous': 1, 'them': 1, 'other': 1, 'manager': 1, 'analyze': 1, 'europe': 1, 'package': 1, 'design': 3, 'phd': 1, 'programming': 1, 'millions': 1, 'publication': 1, 'information': 2, 'software': 1, 'degree': 2, 'responsible': 1, 'deploy': 1, 'easy': 1, 'this': 3, 'thrive': 1, 'android': 1, 'preferably': 2, 'rms': 2, 'pytorch': 1, 'ireland': 1, 'devices': 1, 'arabic': 1, 'focus': 1, 'following': 2, 'user': 1, 'capabilities': 2, 'distribution': 1, 'right': 1, 'multinational': 1, 'aligned': 1, 'advancements': 1, 'java': 1, 'especially': 1, 'am': 1, 'elasticsearch': 1, 'if': 2, 'machine': 1, 'crafting': 1, 'colleagues': 1, 'spring': 1, 'best': 1, 'marketplace': 1, 'where': 1, 'practices': 1, 'vector': 1, 'offline': 1, 'complex': 2, 'stay': 1, 'plus': 3, 'train': 1, 'business': 1, 'restful': 1, 'from': 2, 'analysis': 1, 'active': 1, 'related': 3, 'can': 7, 'engines': 1, 'scalable': 1, 'mlops': 1, 'in': 16, 'as': 1, 'engineer': 1, 'prototyping': 1, 'systems': 1, 'ensure': 1, 'america': 1, 'these': 1, 'improve': 1, 'have': 1, 'topics': 1, 'important': 1, 'essence': 1, 'improvements': 1, 'experienced': 1, 'frameworks': 1, 'our': 5, 'we': 1, 'researchers': 1, 'accurate': 1, 'learning': 5, 'minimum': 2, 'developers': 1, 'looking': 1, 'efficient': 2, 'computer': 1, 'excellent': 1, 'ai': 1, 'search': 12, 'carry': 1, 'semantic': 2, 'specialized': 1, 'tasks': 1, 'academic': 1, 'out': 1, 'million': 2, 'dl': 1, 'retrieval': 5, 'ir': 1, 'fluency': 1, 'problems': 1, 'description': 1, 'closely': 1, 'africa': 1, 'application': 2, 'outputs': 1, 'using': 2, 'engineering': 1, 'huawei': 3, 'by': 2, 'operating': 1, 'services': 3, 'libraries': 1, 'culture': 1, 'years': 1, 'patents': 1, 'online': 1, 'into': 2, 'developed': 1, 'conferences': 1, 'i': 1, 'talented': 1, 'optimize': 2, 'strong': 1, 'deep': 4, 'with': 8, 'collaborate': 1, 'form': 1, 'suggestions': 1, 'project': 1, 'work': 4, 'part': 1, 'products': 1, 'system': 1, 'turkey': 1, 'papers': 1, 'integrating': 1, 'chance': 1, 'teams': 2, 'are': 1, 'an': 1, 'science': 1, 'redis': 1, 'skills': 2, 'innovative': 1, 'be': 2, 'proven': 1, 'of': 9, 'level': 1, 'research': 2, 'environment': 1, 'guide': 1, 'techniques': 2, 'singapore': 1, 'produce': 1, 'big': 1, 'nlp': 7, 'talks': 1, 'fields': 1, 'or': 5, 'russia': 1, 'and': 25, 'see': 1, 'recommendation': 4, 'russian': 1, 'integrate': 1, 'asia': 1, 'what': 2, 'english': 1, 'functionality': 1, 'records': 1, 'perfect': 2, 'address': 1, 'projects': 1, 'ms': 1, 'affect': 1, 'updated': 1, 'industry': 2, 'tensorflow': 1, 'communicate': 1, 'directly': 1, 'build': 1, 'users': 2, 'for': 10, 'the': 13, 'requirements': 3, 'platform': 2, 'modeling': 1, 'is': 7, 'experience': 7, 'used': 1, 'enhance': 1, 'conduct': 1, 'allows': 1, 'junior': 1, 'development': 1, 'task': 1, 'rdbms': 1, 'delivering': 1, 'you': 10, 'driven': 1, 'improving': 1, 'dense': 1, 'independently': 1, 'markets': 1, 'team': 4, 'qualifications': 1, 'within': 3, 'then': 1, 'data': 2, 'role': 4, 'implement': 1, 'production': 1, 'technologies': 1, 'maintainable': 1, 'engineers': 1, 'hand': 1, 'models': 3, 'appgallery': 5, 'a': 8, 'expect': 2, 'fit': 3, 'python': 1, 'at': 2}\n"
     ]
    }
   ],
   "source": [
    "def count_dict(sentences):\n",
    "    count_dict = {}\n",
    "    for word in word_set:\n",
    "        count_dict[word] = 0\n",
    "    for sent in sentences:\n",
    "        for word in sent:\n",
    "            count_dict[word] += 1\n",
    "    return count_dict\n",
    "word_count = count_dict(sentences)\n",
    "print(word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b544b8cc",
   "metadata": {},
   "source": [
    "### term frequenct calculation in the corpus- TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b277c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(document, word):\n",
    "    N = len(document)\n",
    "    occurance = len([token for token in document if token == word])\n",
    "    return occurance / N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5653c77d",
   "metadata": {},
   "source": [
    "### inverse document frequency in the corpus-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "990fdd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_document_frequency(word):\n",
    "    try:\n",
    "        word_occurance = word_count[word] + 1\n",
    "    except:\n",
    "        word_occurance = 1\n",
    "    return np.log(total_docs / word_occurance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f792b7df",
   "metadata": {},
   "source": [
    "### combining tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f68c311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(sentence):\n",
    "    vec = np.zeros((len(word_set),))\n",
    "    for word in sentence:\n",
    "        tf = term_frequency(sentence, word)\n",
    "        idf = inverse_document_frequency(word)\n",
    "        vec[word_index[word]] = tf * idf\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a2c4a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4632905e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.00143806, -0.00455856, -0.00455856, -0.00143806, -0.00143806,\n",
      "       -0.00143806, -0.05670949, -0.00455856, -0.00862839, -0.00143806,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00862839, -0.00143806, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00143806, -0.00455856, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00862839, -0.00143806, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00455856, -0.00143806, -0.00455856, -0.00143806, -0.00143806,\n",
      "       -0.00143806, -0.00862839, -0.00143806, -0.00143806, -0.00455856,\n",
      "       -0.00455856, -0.00143806, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00143806, -0.00455856, -0.00143806, -0.00455856, -0.00143806,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.00455856, -0.00143806,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.00143806, -0.00455856,\n",
      "       -0.00143806, -0.00862839, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00455856, -0.00143806, -0.00143806, -0.00862839, -0.03019936,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.09404858, -0.00143806,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.00143806, -0.01858672,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.01858672, -0.00455856,\n",
      "       -0.00143806, -0.00143806, -0.00455856, -0.00143806, -0.00143806,\n",
      "       -0.00143806, -0.06385766, -0.00143806, -0.00455856, -0.00143806,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.00455856, -0.00143806,\n",
      "       -0.01858672, -0.00143806, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00143806, -0.00143806, -0.00455856, -0.00143806, -0.00455856,\n",
      "       -0.00143806, -0.00862839, -0.00455856, -0.00143806, -0.00862839,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00455856, -0.00143806, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00455856, -0.00143806, -0.01335633, -0.03646846, -0.00143806,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.01335633, -0.00143806,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00143806, -0.00455856, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00143806, -0.00455856, -0.00143806, -0.00455856, -0.00143806,\n",
      "       -0.04299433, -0.00143806, -0.00455856, -0.00143806, -0.00143806,\n",
      "       -0.00455856, -0.00143806, -0.00143806, -0.00143806, -0.03019936,\n",
      "       -0.00143806, -0.00143806, -0.01858672, -0.00143806, -0.16898841,\n",
      "       -0.00143806, -0.01335633, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00455856, -0.00143806, -0.00143806, -0.00143806, -0.00455856,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00455856, -0.00143806, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00455856, -0.04974886, -0.07117789, -0.00862839, -0.00455856,\n",
      "       -0.00143806, -0.03019936, -0.03019936, -0.00143806, -0.00143806,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00143806, -0.00143806, -0.04974886, -0.00143806, -0.00143806,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.01335633, -0.00143806,\n",
      "       -0.00862839, -0.00143806, -0.00455856, -0.01335633, -0.00143806,\n",
      "       -0.00143806, -0.00143806, -0.00143806, -0.00143806, -0.00143806,\n",
      "       -0.00862839, -0.01858672, -0.03646846, -0.00455856, -0.00862839,\n",
      "       -0.00143806, -0.00455856])]\n"
     ]
    }
   ],
   "source": [
    "vectors = []\n",
    "for sent in sentences:\n",
    "    vectors.append(tf_idf(sent))\n",
    "\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457bc6fa",
   "metadata": {},
   "source": [
    "#### Bu çıktı, vectors listesinin içindeki her bir TF-IDF vektörünü içerir. Her vektör, cümle içindeki \n",
    "#### her kelimenin TF-IDF skorunu içeren bir liste olarak temsil edilir. TF-IDF skorları, belirli bir cümlenin\n",
    "#### içindeki kelimelerin önem sırasını belirlemeye yardımcı olan istatistiksel bir ölçümdür."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069aabe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
